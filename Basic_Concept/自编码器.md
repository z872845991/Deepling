# 自编码器

> **自编码**，也称自动编码器，是一种[人工神经网络](https://zh.wikipedia.org/wiki/人工神经网络)，在[无监督学习](https://zh.wikipedia.org/wiki/無監督式學習網路)中用于[有效编码](https://zh.wikipedia.org/wiki/表征学习)。自编码的目的是对一组数据学习出一种表示（也称表征，编码），通常用于[降维](https://zh.wikipedia.org/wiki/維度減化)。最近，自编码的概念广泛地用于数据的[生成模型](https://zh.wikipedia.org/wiki/生成模型)。[[1\]](https://zh.wikipedia.org/wiki/自编码器#cite_note-VAE-1)[[2\]](https://zh.wikipedia.org/wiki/自编码器#cite_note-gan_faces-2) 自2010年以来，一些先进的人工智能在[深度学习](https://zh.wikipedia.org/wiki/深度学习)网络中采用了采用堆叠式稀疏自编码。[[3\]](https://zh.wikipedia.org/wiki/自编码器#cite_note-domingos-3)

- **自动编码器是资料相关的（data-specific或data-dependent）**，这意味着自动编码器只能压缩那些与训练资料类似的资料。比如，使用人脸训练出来的自动编码器在压缩别的图片，比如树木时效能很差，因为它学习到的特征是与人脸相关的。
- **自动编码器是有损的**，意思是解压缩的输出与原来的输入相比是退化的，MP3，JPEG等压缩演算法也是如此。这与无损压缩演算法不同。
- **自动编码器是从资料样本中自动学习的**，这意味着很容易对指定类的输入训练出一种特定的编码器，而不需要完成任何新工作。

搭建一个自动编码器需要完成下面三样工作：搭建编码器，搭建解码器，设定一个损失函数，用以衡量由于压缩而损失掉的信息。编码器和解码器一般都是参数化的方程，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化，例如SGD。

[知乎专栏](https://zhuanlan.zhihu.com/p/80377698)



